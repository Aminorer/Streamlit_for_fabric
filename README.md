# Streamlit for Fabric

Cette application Streamlit interagit avec des bases de donn√©es SQL pour afficher des historiques et des pr√©dictions de stocks.

## Chargement des donn√©es

Les jeux de donn√©es factices ont √©t√© supprim√©s. Toutes les informations sont d√©sormais r√©cup√©r√©es directement depuis la base via les fonctions `load_hist_data` et `load_prediction_data` du module `db_utils`.
`load_hist_data` lit les volumes historiques tandis que `load_prediction_data` charge une table de pr√©dictions en validant son nom et propose les m√™mes filtres (marques, saisons, dimensions, dates).

```python
from db_utils import load_hist_data, load_prediction_data

df_hist = load_hist_data(brands=["MICHELIN"])
df_pred = load_prediction_data("pred_amz_man", brands=["MICHELIN"])
```

## Pages

L'application propose plusieurs pages accessibles depuis le menu :

- **Analyse comparative** (`pages/1_Analyse_Comparative.py`) ‚Äî comparaison de l'historique avec plusieurs s√©ries de pr√©dictions et calcul de pr√©cision hebdomadaire.
- **Gestion des ruptures** (`pages/1_Gestion_Ruptures.py`) ‚Äî suivi des dates de rupture principales et des recommandations de commande.
- **Analyse des pr√©dictions** (`pages/1_Analyse_Prediction.py`) ‚Äî r√©partition des statuts de stock et scores de criticit√©.
- **Analyse des prix** (`pages/2_Analyse_Prix.py`) ‚Äî opportunit√©s de marge et tendances de prix.
- **Volatilit√© & risques** (`pages/3_Volatilite_Risques.py`) ‚Äî √©tats de volatilit√© et alertes associ√©es.

## Analyse comparative

Cette page confronte l'historique des volumes aux diff√©rentes s√©ries de pr√©dictions disponibles.
Elle permet de filtrer par marque, saison, dimension et p√©riode, puis¬†:

- superpose les quantit√©s historiques et chaque s√©rie `stock_prediction*` dans un graphique ;
- calcule la pr√©cision hebdomadaire (1¬†‚àí¬†MAPE) et affiche son √©volution ;
- exporte les donn√©es combin√©es au format CSV.

Les l√©gendes du graphique utilisent des ic√¥nes ("üìà" pour l'historique,
"üîÆ" pour les pr√©dictions) afin de faciliter la lecture. Elles peuvent √™tre
d√©sactiv√©es en passant ``use_emoji=False`` √†
``plot_historical_vs_multi_predictions`` ou via la case √† cocher de l'interface.

Les tables de pr√©diction suivent un motif `pred_<plateforme>_<activit√©>_<YYYYMMDD>`¬†:
la date correspond au mardi de g√©n√©ration de la semaine, les pr√©visions √©tant recalcul√©es chaque mardi.
Les visualisations exploitent la palette de couleurs Wyz (`ASSOCIATED_COLORS`) d√©finie dans `constants.py` pour assurer une identit√© visuelle homog√®ne.

## Colonnes cl√©s

Les tables de pr√©diction exposent notamment :

- `stock_status` : statut calcul√© du stock (OK, RUPTURE, etc.).
- `criticality_score` : niveau de criticit√© d'un article.
- `main_rupture_date`, `optimal_order_date`, `last_safe_order_date` : jalons de la cha√Æne d‚Äôapprovisionnement.
- `order_recommendation`, `tension_days`, `recommended_volume` : informations de planification.
- `margin_opportunity_days` : nombre de jours avant une hausse de prix potentielle.
- `volatility_status`, `volatility_type`, `risk_level`, `anomaly_alert` : indicateurs de risque.

## Fabric / Delta

L'acc√®s aux Lakehouses Fabric se fait via leurs SQL endpoints. Les variables
`SQL_SERVER_HIST` et `SQL_SERVER_PRED` doivent pointer respectivement vers les
endpoints des deux Lakehouses historiques et pr√©dictifs. Utilisez un pilote
ODBC compatible, par exemple `ODBC Driver 18 for SQL Server`. Les tables Delta
sont expos√©es dans `INFORMATION_SCHEMA.TABLES` sous le sch√©ma `dbo`.

## Configuration de d√©veloppement

### Variables d'environnement requises

Les informations de connexion sont fournies via des variables d'environnement (par exemple dans `secret.env`).
Un fichier d'exemple `secret.env.example` est disponible √† la racine¬†: copiez-le en `secret.env` et renseignez vos propres valeurs, puis ajustez les variables suivantes¬†:

- `SQL_USER` ‚Äì Nom d'utilisateur SQL.
- `SQL_PASSWORD` ‚Äì Mot de passe SQL.
- `SQL_DRIVER` ‚Äì Pilote ODBC √† utiliser.
- `SQL_SERVER_HIST` ‚Äì Adresse du serveur h√©bergeant les donn√©es historiques.
- `SQL_DATABASE_HIST` ‚Äì Base contenant les donn√©es historiques.
- `SQL_SERVER_PRED` ‚Äì Adresse du serveur des tables de pr√©diction.
- `SQL_DATABASE_PRED` ‚Äì Base contenant les tables de pr√©diction.

Les variables g√©n√©riques `SQL_SERVER` et `SQL_DATABASE` ne sont plus prises en
charge¬†; vous devez d√©finir explicitement les quatre variables ci-dessus.

### Conventions de nommage des tables

Les tables historiques suivent le motif `fullsize_stock_hist_%` et les tables de pr√©diction le motif `pred_%`. Les suffixes doivent correspondre pour former une paire coh√©rente, par exemple¬†: `fullsize_stock_hist_amz_man` et `pred_amz_man`.

Les types d'activit√© valides sont¬†:

- `man`¬†‚Äì activit√©s manufacturi√®res ;
- `dis`¬†‚Äì activit√©s de distribution ;
- `mixte`¬†‚Äì activit√©s mixtes combinant les deux.

Ces valeurs forment la partie ¬´¬†activit√©¬†¬ª des noms de table.

### Cr√©ation et alimentation des tables de test

Pour le d√©veloppement ou les tests locaux, cr√©ez une paire de tables historique/pr√©diction respectant les conventions ci-dessus. Exemple minimal¬†:

```sql
-- Table historique
CREATE TABLE dbo.fullsize_stock_hist_demo (
    date       DATE,
    brand      VARCHAR(50),
    sku        VARCHAR(50),
    stock_qty  INT
);
INSERT INTO dbo.fullsize_stock_hist_demo VALUES ('2024-01-01','MICHELIN','XYZ',100);

-- Table de pr√©diction correspondante
CREATE TABLE dbo.pred_demo (
    date              DATE,
    brand             VARCHAR(50),
    sku               VARCHAR(50),
    stock_qty         INT,
    stock_status      VARCHAR(20),
    criticality_score FLOAT
);
INSERT INTO dbo.pred_demo VALUES ('2024-01-01','MICHELIN','XYZ',100,'OK',0.1);
```

Ces tables de test peuvent ensuite √™tre interrog√©es via les fonctions `load_hist_data` et `load_prediction_data`.

## Tests

Executez la suite de tests avec [pytest](https://pytest.org/):

```bash
pytest tests/
```
